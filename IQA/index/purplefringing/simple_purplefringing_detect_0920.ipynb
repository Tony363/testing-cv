{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import cv2 as cv\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 夜景偵測\r\n",
    "### 通常紫邊會發生在白天戶外或是光線充足的光源旁，故先將histogram集中在較低Pixel的照片排除，避免後續演算法錯估。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def night_view_detect(img_input):\r\n",
    "    if img_input.mean() < 80 and img_input.std() < 60:\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 色偏偵測\r\n",
    "### 排除掉整張照片偏藍且缺乏綠色，避免因紫光或是紫色物體影響結果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def colour_purple_cast_detect(img_input):\r\n",
    "    img_input_float = img_input.astype(np.float32) / 255.0\r\n",
    "    # np_Y = 0.229 * img_input_float[:, :, 2] + 0.587*img_input_float[:, :, 1] + 0.114*img_input_float[:, :, 0] \r\n",
    "    np_Cb = -0.169 * img_input_float[:, :, 2] - 0.331*img_input_float[:, :, 1] + 0.5*img_input_float[:, :, 0]\r\n",
    "    np_Cr = 0.5 * img_input_float[:, :, 2] - 0.419*img_input_float[:, :, 1] - 0.081*img_input_float[:, :, 0]\r\n",
    "\r\n",
    "    # count purple distance\r\n",
    "    np_p_diff_Cb = np_Cb - 0.331\r\n",
    "    np_p_diff_Cr = np_Cr - 0.42\r\n",
    "\r\n",
    "    np_p_dist = np.sqrt(np_p_diff_Cb * np_p_diff_Cb + np_p_diff_Cr * np_p_diff_Cr)\r\n",
    "\r\n",
    "    # count green distance\r\n",
    "    np_g_diff_Cb = np_Cb + 0.331\r\n",
    "    np_g_diff_Cr = np_Cr + 0.42\r\n",
    "\r\n",
    "    np_g_dist = np.sqrt(np_g_diff_Cb*np_g_diff_Cb + np_g_diff_Cr*np_g_diff_Cr)\r\n",
    "\r\n",
    "    if (np_p_dist / np_g_dist).mean() < 0.89: # threshold can be [0.88, 0.9]\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 紫邊偵測\r\n",
    "### 參考 Kannan Karthik, Parveen Malik, \"Purple Fringing Aberration Detection Based on Content-Adaptable Thresholds\", \r\n",
    "### Parveen Malik, Kannan Karthik, \"Correction of complex purple fringing by green-channel compensation and local luminance adaptation\"\r\n",
    "### Baek-Kyu Kim, Rae-Hong Park, \"AUTOMATIC DETECTION AND CORRECTION OF PURPLE FRINGING USING THE GRADIENT INFORMATION AND DESATURATION\"\r\n",
    "### 這些 paper 方法"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def purple_fringing_detect(img_input):\r\n",
    "    # get HSV purple region\r\n",
    "    # ===================================\r\n",
    "    img_HSV = cv.cvtColor(img_input, cv.COLOR_BGR2HSV)\r\n",
    "    low = np.array([120, 20, 20])\r\n",
    "    high = np.array([140, 255, 255])\r\n",
    "    mask_HSV_purple = cv.inRange(img_HSV, low, high)\r\n",
    "\r\n",
    "    # change BGR to YCbCr\r\n",
    "    # get YCbCr purple region\r\n",
    "    # ====================================\r\n",
    "    img_input_float = img_input.astype(np.float32) / 255.0\r\n",
    "    np_Y = 0.229 * img_input_float[:, :, 2] + 0.587*img_input_float[:, :, 1] + 0.114*img_input_float[:, :, 0] \r\n",
    "    np_Cb = -0.169 * img_input_float[:, :, 2] - 0.331*img_input_float[:, :, 1] + 0.5*img_input_float[:, :, 0]\r\n",
    "    np_Cr = 0.5 * img_input_float[:, :, 2] - 0.419*img_input_float[:, :, 1] - 0.081*img_input_float[:, :, 0]\r\n",
    "\r\n",
    "    # according to paper, get YCbCr purple region\r\n",
    "    # count purple distance\r\n",
    "    np_p_diff_Cb = np_Cb - 0.331\r\n",
    "    np_p_diff_Cr = np_Cr - 0.42\r\n",
    "    np_p_dist = np.sqrt(np_p_diff_Cb * np_p_diff_Cb + np_p_diff_Cr * np_p_diff_Cr)\r\n",
    "\r\n",
    "    # count green distance\r\n",
    "    np_g_diff_Cb = np_Cb + 0.331\r\n",
    "    np_g_diff_Cr = np_Cr + 0.42\r\n",
    "    np_g_dist = np.sqrt(np_g_diff_Cb*np_g_diff_Cb + np_g_diff_Cr*np_g_diff_Cr)\r\n",
    "\r\n",
    "\r\n",
    "    kernel = np.ones((5, 5)) / 25\r\n",
    "\r\n",
    "    np_p_dist_2 = cv.filter2D(np_p_dist, -1, kernel)\r\n",
    "    np_g_dist_2 = cv.filter2D(np_g_dist, -1, kernel)\r\n",
    "\r\n",
    "    # 0.9 is a threhold [0.85, 0.95]\r\n",
    "    mask_YCbCr_purple = (np_p_dist_2 / np_g_dist_2) < 0.9\r\n",
    "\r\n",
    "    # intersection HSV and YCbCr purple region \r\n",
    "    # ===================================\r\n",
    "    mask_intersection_purple = (mask_HSV_purple==255) & mask_YCbCr_purple\r\n",
    "\r\n",
    "    # count the neighbor purple region \r\n",
    "    # ===================================\r\n",
    "    w_size = 5\r\n",
    "    kernel = np.ones((w_size, w_size)) / (w_size * w_size)\r\n",
    "\r\n",
    "    channel_list = []\r\n",
    "    for c in range(3):\r\n",
    "        img_channel = img_input[:, :, c] * mask_intersection_purple\r\n",
    "        np_tmp = cv.filter2D(img_channel, -1, kernel)\r\n",
    "        channel_list.append(np_tmp * mask_intersection_purple)\r\n",
    "\r\n",
    "    # check if B > G & B > R, that is purple region\r\n",
    "    mask_purple = (channel_list[1] < channel_list[0]) & (channel_list[1] < channel_list[2])\r\n",
    "\r\n",
    "    # calculate NSRs\r\n",
    "    # min is 0.7\r\n",
    "    # ====================================\r\n",
    "    blur = cv.GaussianBlur(np_Y, (5, 5), 0)\r\n",
    "\r\n",
    "    window_size = 11\r\n",
    "    kernel = np.ones((window_size, window_size))\r\n",
    "\r\n",
    "    mean = blur.mean()\r\n",
    "    std = blur.std()\r\n",
    "    alpha = 1.5\r\n",
    "    threshold = mean + alpha * std\r\n",
    "    threshold = max(threshold, 0.7)\r\n",
    "\r\n",
    "    mask_NSRs = blur > threshold\r\n",
    "\r\n",
    "    mask_expand_NSRs = cv.dilate(mask_NSRs.astype(np.uint8), kernel, iterations = 1)\r\n",
    "\r\n",
    "    # calculate HIGH-CONTRAST NSRs\r\n",
    "    # ===================================\r\n",
    "    sobelx = cv.Sobel(blur, cv.CV_64F, 1, 0, ksize=5)\r\n",
    "    sobely = cv.Sobel(blur, cv.CV_64F, 0, 1, ksize=5)\r\n",
    "\r\n",
    "    M = np.sqrt(sobelx*sobelx + sobely*sobely)\r\n",
    "\r\n",
    "    M_mean = M.mean()\r\n",
    "    M_std = M.std()\r\n",
    "    alpha = 3\r\n",
    "    M_t = M_mean + alpha * M_std\r\n",
    "\r\n",
    "    mask_NSRs_2 = M > M_t    \r\n",
    "\r\n",
    "    mask_expand_NSRs_2 = cv.dilate(mask_NSRs_2.astype(np.uint8), kernel, iterations = 1)\r\n",
    "\r\n",
    "    # intersection 2 HSR mask\r\n",
    "    mask_nearNSR_purple = mask_purple & mask_expand_NSRs & mask_expand_NSRs_2\r\n",
    "\r\n",
    "    # use connected compoent to remove few pixels regions\r\n",
    "    #====================================\r\n",
    "    num_comp, comp_labels, comp_stats, comp_centroid = cv.connectedComponentsWithStats(mask_nearNSR_purple.astype(np.uint8))\r\n",
    "\r\n",
    "    # threshold = total pixels * 10^-5\r\n",
    "    threshold = img_input.shape[0]*img_input.shape[1]*1e-5 # output3=1e-6*5\r\n",
    "    # threshold = img_input.shape[0]*img_input.shape[1]*1e-6*5 \r\n",
    "\r\n",
    "    set_filter = set(np.arange(num_comp) * (comp_stats[:, 4] > threshold))\r\n",
    "    set_filter.remove(0)\r\n",
    "    list_filter = list(set_filter)\r\n",
    "    final_mask = np.isin(comp_labels, list_filter)\r\n",
    "\r\n",
    "    return mask_nearNSR_purple, final_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def draw_purple_fringing(input_image, mask):\r\n",
    "    imask = mask != True\r\n",
    "    img_purple = np.dstack((( 255*mask + input_image[:, :, 0]*imask), \\\r\n",
    "                            (   0*mask + input_image[:, :, 1]*imask), \\\r\n",
    "                            ( 255*mask + input_image[:, :, 2]*imask)))\r\n",
    "    return img_purple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### =========================="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "# intput_path = os.getcwd()+'\\..\\googlephotos\\\\'\r\n",
    "intput_path = os.getcwd()+'\\..\\\\20200428_Rear_Photo\\\\'\r\n",
    "\r\n",
    "d = {}\r\n",
    "\r\n",
    "d[\"Name\"] = []\r\n",
    "d[\"Purple Fringing Pixel\"] = []\r\n",
    "d[\"Purple Fringing Total Ratio\"] = []\r\n",
    "d[\"Purple Fringing Denoise Pixel\"] = []\r\n",
    "d[\"Purple Fringing Denoise Total Ratio\"] = []\r\n",
    "d[\"Purple Fringing Ratio2\"] = []\r\n",
    "d[\"Purple Fringing Ratio3\"] = []\r\n",
    "d[\"Night View\"] = [] # night_view_detect\r\n",
    "d[\"Purple Cast\"] = [] # colour_purple_cast_detect\r\n",
    "\r\n",
    "divided = 8\r\n",
    "\r\n",
    "for filefullname in tqdm(os.listdir(intput_path)):\r\n",
    "   \r\n",
    "    img_orig = cv.imread(intput_path + filefullname)\r\n",
    "\r\n",
    "    d[\"Night View\"].append(night_view_detect(img_orig))\r\n",
    "    d[\"Purple Cast\"].append(colour_purple_cast_detect(img_orig))\r\n",
    "\r\n",
    "    mask, denoise_mask = purple_fringing_detect(img_orig)\r\n",
    "\r\n",
    "    d[\"Name\"].append(filefullname)\r\n",
    "    d[\"Purple Fringing Pixel\"].append(mask.sum())\r\n",
    "    d[\"Purple Fringing Total Ratio\"].append(mask.mean())\r\n",
    "\r\n",
    "    d[\"Purple Fringing Denoise Pixel\"].append(denoise_mask.sum())\r\n",
    "    d[\"Purple Fringing Denoise Total Ratio\"].append(denoise_mask.mean())\r\n",
    "\r\n",
    "    h, w, c = img_orig.shape\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    count2 = 0\r\n",
    "\r\n",
    "    h_space = h // divided\r\n",
    "    w_spzce = w // divided\r\n",
    "\r\n",
    "    for i in range(divided):\r\n",
    "        for j in range(divided):\r\n",
    "            \r\n",
    "            purple_pixels = (mask[i*h_space:(i+1)*h_space, j*w_spzce:(j+1)*w_spzce]).sum()\r\n",
    "\r\n",
    "            purple_ratio = np.round((mask[i*h_space:(i+1)*h_space, j*w_spzce:(j+1)*w_spzce]).mean() * 1e5, 3) \r\n",
    "\r\n",
    "            if purple_ratio != 0:\r\n",
    "                count += 1\r\n",
    "            if purple_ratio > 100:\r\n",
    "                count2 += 1\r\n",
    "    \r\n",
    "    d[\"Purple Fringing Ratio2\"].append(count)\r\n",
    "    d[\"Purple Fringing Ratio3\"].append(count2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 152/152 [09:22<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import pandas as pd\r\n",
    "df = pd.DataFrame(d)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "4925a5c1e05e6e730d7b240fac92ecee7ad5392db8fb5267bc939e853323d4cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}